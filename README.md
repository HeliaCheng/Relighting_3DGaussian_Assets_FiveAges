**This Repository test run up-to-date mainstream BRDF-based relightable 3d gaussians with 3d gaussian models as input. New functins are added in gaussian models, main pipeline and the parameters setting.**

# Usage

##  Environment

For Relightable3DGaussian，the environment name is r3dx, for GIR, the environment name is gir. If you need to create the environment all over, please see their original repositories. https://github.com/guduxiaolang/gir https://github.com/NJU-3DV/Relightable3DGaussian

##  Get RGB GT images & camera poses(R_c2w +T_w2c as 4*4 matrises)

This instructs how to get GT images from the input ply file using `render_img_cam_obj.py`. For each object, it generates customer-defined number of views following both `fibonacci` and `ring` trajectories.  
1.**Directory designation**  
Change the code below (around line 371-375) in render_cam_img_obj.py, to the correct directories where you store the ply file and the output.
```
renderer = GaussianRenderer(opt=opt, scene_dir="../Relightable3DGaussian/FA_scene/gs_results", sh_degree=0)
renderer.load_models(target="chair.ply")
output_base_dir = "../Relightable3DGaussian/FA_scene/gs_results/chair_bl"
```
The output file would be stored inside the `output_base_dir` you defined, and the default folders created are `img` and `cam`, 
2.**Number of views** 
Change the code below (`main` section of file) to customize how many views you need for each trajectories. (We use 200 fibonacci views for training and 100 ring views for testing.)
```
sample_fibo = 200  
ring_count=100
```
3.**Rendering Properties** 
You can change the default** image height and width** in ` _make_camera_from_pos`:
Notice the camera model in each project differs in** camera intrinsics**, here you can change fx,fy,cx,cy or FovX,FoVy. The default settings are FovX=FoVy=90 degree, cx=cy=fx=fy=512.
Another notice is since this py file adopts gaussian renderer from the project, for GIR, it doesn't provide the shs color in the first run, so addtional adjustemnts in `gaussian_renderer/__init__.py` need to be done as follows:
change line 89: `shs=None` to `shs=shs` and line 125 `colors_precomp = colors_precomp` to `colors_precomp=None`·
If you wish to render images with black/white **background**, adjust them in `./arguments/__init__.py`. If you prefer other colors, adjust bg_color in the file. 
Adjust the **radius** of trajectories, adjust radius in `render_cam_and_img` function.

4.**run** inference directly using the provided script.
```
python render_cam_img_obj.py
```
##  Generate binary masks
1. use rembg (if not installed, conda install rembg) to get non-binary masks first.
 ```
 sh ./rembg.sh
 ```
2. Refine the masks into binary version.
Adjust the threshold as you wish. This py file processes the non-binary masks generated by rembg.
```
python mask_refiner.py
```
## Train the relightable model using 3dgs input

Run the following script.
```
sh train_reli.sh #GIR
sh train.py -t render --is_ply "True" #Relightable3dGaussian,don't forget to customize directories in training_new
sh train.py -t neilf -c <your checkpoint path>#Relightable3DGaussian
```
`python inference.py --data_path examples/Courtroom  --save_path <your/output/dir>`

## Relight the model
Run the following script:
```
python relighting.py #Relightable3DGaussian
sh relighting.sh #GIR
```
